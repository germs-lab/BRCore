---
title: "Introduction to BRCore"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction to BRCore}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7, 
  fig.height = 6
)
```

# Load R libraries

```{r setup, echo=TRUE}
# Try to load installed package; if not installed, load from source
if (!requireNamespace("BRCore", quietly = TRUE)) {
  message("BRCore not installed; loading from source with devtools::load_all()")
  devtools::load_all("..")  # or "." if the vignette is in vignettes/ and wd is package root
} else {
  library(BRCore)
}
```

BRCore comes with a few datasets. Three 16S dtasets: `switchgrass`, `mimulus`, and
`bean`, from Shade and Stopnisek 2019 and 16S dataset, called `bcse`, from leaves 
of the Bioenergy Crop Research Experiment from Haan et al. 2023. Here we are going
to use `bcse` since it is not rarefied in contrast of the other three.

```{r load bcse, echo=TRUE}
data("bcse", package = "BRCore")
str(bcse)
```

# Preprocessing

We are not going to talk about the importance of rarefaction as it is not the goal
of these vignette but if you are ineterested you should read 
To identified the ideal rarefaction cutoff we propose a series of visuals to guide
in the decision. As we all know it is impossible to have perfect depth and some
samples will seqquence worse than other for reasons it is hard to control. 

To decide how many samples we are accepting to discard and how much diversity we
want to retain we can look at generated metrics below.

```{r calculate metrics, echo=TRUE}
bcse_metrics <- add_rarefaction_metrics(data = bcse)
bcse_metrics
```

and plot

```{r plot metrics, echo=TRUE}
rarefaction_plot <- plot_rarefaction_metrics(bcse_metrics)
print(rarefaction_plot)
```

# Perform mutiple rarefaction

The best way to rarefy your data is to use the multiple rarefaction approach. Originally
developed by Sanders in 1968 it has been adopted widely in ecology research. 

```{r rarefy bcse, echo=TRUE}
bcse_rarefied_otutable <-
    multi_rarefy(
        physeq = bcse,
        depth_level = 1000,
        num_iter = 100,
        threads = 8,
        set_seed = 7642
        )
```

We can then inspect that everyhting looks good before going further 

```{r verify success rarefaction, echo=TRUE}
rowSums(bcse_rarefied_otutable)
bcse_rarefied_otutable[1:10, 1:10]
```


### Recreate a phyloseq object with rarefied `otu_table()` 

You can then use the function below to replace the `otu_table()` with the rarefied
table you just created. Or, you can create a new object with rarefied otu_table.

```{r replace otu table, echo=TRUE}
bcse_rare <-
    do_phyloseq(physeq = bcse, 
                otu_rare = bcse_rarefied_otutable)

bcse_rare
sample_sums(bcse_rare)
```


### Extracting the core OTU/ASV set

One way to systematically explore the abundance and occupancy inclusion thresholds used to define the core microbiome is to evaluate how well the resulting core membership captures the overarching patterns of beta diversity found in the complete dataset. This approach treats the core microbiome as a representative subset that should preserve the main ecological relationships and sample-to-sample differences observed when using all taxa. By measuring how closely the beta diversity patterns calculated from core taxa alone match those from the full dataset, researchers can objectively assess whether their chosen thresholds produce a meaningful and informative core that maintains the essential structural information of the microbial community while reducing complexity.

To identify the optimal point where increasing the core inclusion threshold provides diminishing returns in explanatory value, we offer two automated methods. 

1) The first is a more stringent `elbow` approach that finds the bend in the abundance-occupancy curve where adding more taxa yields progressively smaller improvements. This method calculates the first-order difference (numerical differentiation) by assigning a score to each potential cutoff point, splitting the curve into two parts, and finding the point that maximizes the difference in average rates of change between these parts. 

2) The second method uses a final percent `increase` threshold in beta-diversity (we recommend 2% or more), which continues adding taxa until improvements fall below this percentage. 

Both methods measure improvement using Bray-Curtis similarity through the equation `C = 1 - (BC_core/BC_all)`, where `C` represents the contribution of ranked taxa to total similarity, `BC_core` is the Bray-Curtis similarity using only core taxa, and `BC_all` uses the complete dataset. 

The cumulative explanatory value of adding each next-ranked taxon can be plotted using the plot_bc_increase function, with the red line indicating the elbow method cutoff and colored lines showing the 2% threshold cutoff. These approaches eliminate the need for subjective threshold setting by automatically identifying natural breakpoints where additional taxa provide marginal returns in explanatory power.

The output is a list with 7 datasets... 

```{r extract_core-Globalpatterns elbow, echo=TRUE}

# Setting this to be run later... Check failing on MacOS on Github.

```

```{r extract_core bcse, echo=TRUE}

```




